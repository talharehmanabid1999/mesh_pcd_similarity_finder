{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8abb23-ea01-43cc-b6aa-8aac9be978ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main_process(ranking_dict,distance_dict, voxel_size, aspect_ratio_threshold, cube_size, pcds_down_mapped):\n",
    "#     combined_ratio_dict = {}\n",
    "#     index = 1\n",
    "#     # Iterate over each part in ranking_dict\n",
    "#     for source_filename_stl, similar_parts_stl in ranking_dict.items():\n",
    "        \n",
    "#         # Replace the .stl extension with .pcd for the source filename\n",
    "#         source_filename_pcd = source_filename_stl.replace('.stl', '.pcd')\n",
    "#         source_pcd = pcds_down_mapped[source_filename_pcd]\n",
    "\n",
    "#         aspect_ratio_source = calculate_aspect_ratio(source_pcd)\n",
    "#         if aspect_ratio_source > aspect_ratio_threshold:\n",
    "#             # Fetch top 50 tuples from the distance_dict for the given source file\n",
    "#             if source_filename_stl in distance_dict:\n",
    "#                 top_similar_parts_by_distance = distance_dict[source_filename_stl][:50]\n",
    "#                 # Update combined_ratio_dict with these parts\n",
    "#                 combined_ratio_dict[source_filename_pcd] = top_similar_parts_by_distance\n",
    "#             continue\n",
    "#         top_similar_parts_stl = similar_parts_stl[:50]  # Get top 50 similar parts    \n",
    "#         for target_filename_stl in top_similar_parts_stl:\n",
    "#             target_filename_pcd = target_filename_stl.replace('.stl', '.pcd')\n",
    "#             target_pcd = pcds_down_mapped[target_filename_pcd]\n",
    "#             aspect_ratio_target = calculate_aspect_ratio(target_pcd)\n",
    "#             if aspect_ratio_target > aspect_ratio_threshold:\n",
    "#                 update_metrics(combined_ratio_dict, source_filename_pcd, target_filename_pcd, 1)\n",
    "#                 continue                \n",
    "#             # Get deep copies for comparison and possible cropping\n",
    "#             source_pcd_copy = copy.deepcopy(source_pcd)\n",
    "#             target_pcd_copy = copy.deepcopy(target_pcd)\n",
    "\n",
    "#             # Crop dimension if needed\n",
    "#             # source_copy, target_copy,same_flag = crop_dimension_if_needed(source_extents, target_extents, source_pcd_copy, target_pcd_copy)\n",
    "            \n",
    "#             source, target, source_down, target_down, source_fpfh, target_fpfh = prepare_dataset(\n",
    "#                 voxel_size, [source_pcd_copy, target_pcd_copy])\n",
    "            \n",
    "#             result_ransac = execute_global_registration(\n",
    "#                 source_down, target_down, source_fpfh, target_fpfh, voxel_size, aspect_ratio_threshold)\n",
    "            \n",
    "#             # Assuming result_ransac and result_icp operations are successful\n",
    "#             if result_ransac:\n",
    "#                 source_down.transform(result_ransac.transformation)\n",
    "#                 result_icp = refine_registration_with_icp(source_down, target_down, voxel_size)\n",
    "#                 source_down.transform(result_icp.transformation)\n",
    "#                 combined_ratio = calculate_and_visualize_subtracted_point_clouds(\n",
    "#                 source_down, target_down, voxel_size)  # Assuming this function calculates the combined ratio\n",
    "#                 update_metrics(combined_ratio_dict, source_filename_pcd, target_filename_pcd, combined_ratio) \n",
    "#             # o3d.visualization.draw_geometries([source_down, target_down])                           \n",
    "#         print(index,'# ',source_filename_stl,'done')\n",
    "#         index = index +1\n",
    "#     # Rank the results based on the new combined ratios\n",
    "#     combined_ratio_ranking = rank_metrics(combined_ratio_dict, lower_better=True)\n",
    "#     return combined_ratio_ranking\n",
    "\n",
    "# def calculate_and_visualize_subtracted_point_clouds(source, target, voxel_distance):\n",
    "#     # Build KD-Trees for both point clouds\n",
    "#     source_kd_tree = o3d.geometry.KDTreeFlann(source)\n",
    "#     target_kd_tree = o3d.geometry.KDTreeFlann(target)\n",
    "    \n",
    "#     # Find source points close to any target point\n",
    "#     source_close_indices = set()\n",
    "#     for i, point in enumerate(source.points):\n",
    "#         _, idx, _ = target_kd_tree.search_radius_vector_3d(point, voxel_distance)\n",
    "#         if len(idx) > 0:\n",
    "#             source_close_indices.add(i)\n",
    "    \n",
    "#     # Find target points close to any source point\n",
    "#     target_close_indices = set()\n",
    "#     for i, point in enumerate(target.points):\n",
    "#         _, idx, _ = source_kd_tree.search_radius_vector_3d(point, voxel_distance)\n",
    "#         if len(idx) > 0:\n",
    "#             target_close_indices.add(i)\n",
    "    \n",
    "#     # Create new point clouds for the remaining points\n",
    "#     remaining_source_points = [source.points[i] for i in range(len(source.points)) if i not in source_close_indices]\n",
    "#     remaining_target_points = [target.points[i] for i in range(len(target.points)) if i not in target_close_indices]\n",
    "    \n",
    "#     remaining_source = o3d.geometry.PointCloud()\n",
    "#     remaining_source.points = o3d.utility.Vector3dVector(remaining_source_points)\n",
    "#     remaining_target = o3d.geometry.PointCloud()\n",
    "#     remaining_target.points = o3d.utility.Vector3dVector(remaining_target_points)\n",
    "    \n",
    "#     # Visualize\n",
    "#     remaining_source.paint_uniform_color([1, 0, 0])  # Red for source\n",
    "#     remaining_target.paint_uniform_color([0, 1, 0])  # Green for target\n",
    "#     o3d.visualization.draw_geometries([remaining_source, remaining_target])\n",
    "    \n",
    "#     # Calculate the ratio of remaining points\n",
    "#     total_points = len(source.points) + len(target.points)\n",
    "#     total_remaining_points = len(remaining_source_points) + len(remaining_target_points)\n",
    "#     combined_ratio = total_remaining_points / total_points\n",
    "    \n",
    "#     return combined_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd667fab-ed9e-45c7-aa99-9136a9e9abd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cac7abcf-e6e2-4ee5-abeb-e11825e1d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_aspect_ratio(pcd):\n",
    "    obb = pcd.get_oriented_bounding_box()\n",
    "    extents = np.sort(obb.extent)  # Sort extents to ensure consistent order\n",
    "    aspect_ratio = extents[-1] / extents[0]  # Longest dimension over shortest\n",
    "    return aspect_ratio\n",
    "\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "    pcd_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 2, max_nn=30))\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 5, max_nn=50))\n",
    "    return pcd_down, pcd_fpfh\n",
    "\n",
    "def execute_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size, aspect_ratio_threshold):\n",
    "    aspect_ratio_source = calculate_aspect_ratio(source_down)\n",
    "    aspect_ratio_target = calculate_aspect_ratio(target_down)\n",
    "    \n",
    "    # if aspect_ratio_source > aspect_ratio_threshold or aspect_ratio_target > aspect_ratio_threshold:\n",
    "    #     # print(\"Skipping RANSAC due to high aspect ratio\")\n",
    "    #     return None  # Skipping RANSAC, might need additional handling based on your workflow\n",
    "    \n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh, True,\n",
    "        distance_threshold,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "        3, [\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(distance_threshold),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "        ], o3d.pipelines.registration.RANSACConvergenceCriteria(50000, 0.999))\n",
    "    return result\n",
    "\n",
    "def refine_registration_with_icp(source, target, voxel_size):\n",
    "    distance_threshold = voxel_size * 5\n",
    "    icp_criteria = o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=500)\n",
    "    icp_result = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, distance_threshold, np.eye(4),\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(), icp_criteria)\n",
    "    return icp_result\n",
    "\n",
    "def calculate_and_visualize_subtracted_point_clouds(source, target, voxel_distance):\n",
    "    # Build KD-Trees for both point clouds\n",
    "    source_kd_tree = o3d.geometry.KDTreeFlann(source)\n",
    "    target_kd_tree = o3d.geometry.KDTreeFlann(target)\n",
    "    \n",
    "    # Find source points close to any target point\n",
    "    source_close_indices = set()\n",
    "    for i, point in enumerate(source.points):\n",
    "        _, idx, _ = target_kd_tree.search_radius_vector_3d(point, voxel_distance)\n",
    "        if len(idx) > 0:\n",
    "            source_close_indices.add(i)\n",
    "    \n",
    "    # Find target points close to any source point\n",
    "    target_close_indices = set()\n",
    "    for i, point in enumerate(target.points):\n",
    "        _, idx, _ = source_kd_tree.search_radius_vector_3d(point, voxel_distance)\n",
    "        if len(idx) > 0:\n",
    "            target_close_indices.add(i)\n",
    "    \n",
    "    # Create new point clouds for the remaining points\n",
    "    remaining_source_points = [source.points[i] for i in range(len(source.points)) if i not in source_close_indices]\n",
    "    remaining_target_points = [target.points[i] for i in range(len(target.points)) if i not in target_close_indices]\n",
    "\n",
    "    \n",
    "    # Calculate the ratio of remaining points\n",
    "    total_points = len(source.points) + len(target.points)\n",
    "    total_remaining_points = len(remaining_source_points) + len(remaining_target_points)\n",
    "    combined_ratio = total_remaining_points / total_points\n",
    "    \n",
    "    return combined_ratio\n",
    "\n",
    "\n",
    "def prepare_dataset(voxel_size, pcds_o3d):\n",
    "    source = pcds_o3d[0]\n",
    "    target = pcds_o3d[1]\n",
    "    source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n",
    "    return source, target, source_down, target_down, source_fpfh, target_fpfh\n",
    "\n",
    "def scale_point_cloud(pcd, scale_factors):\n",
    "    \"\"\"\n",
    "    Scale the point cloud by the given scale factors.\n",
    "    This is a placeholder function. You should replace it with actual scaling logic.\n",
    "    \"\"\"\n",
    "    points = np.asarray(pcd.points)\n",
    "    scaled_points = points * scale_factors  # Apply scaling\n",
    "    pcd_scaled = o3d.geometry.PointCloud()\n",
    "    pcd_scaled.points = o3d.utility.Vector3dVector(scaled_points)\n",
    "    return pcd_scaled\n",
    "\n",
    "\n",
    "def get_centroid(pcd):\n",
    "    \"\"\"Compute the centroid of a point cloud.\"\"\"\n",
    "    return np.asarray(pcd.points).mean(axis=0)\n",
    "\n",
    "def translate_point_cloud(pcd, translation):\n",
    "    \"\"\"Translate a point cloud by a given translation vector.\"\"\"\n",
    "    translated_pcd = pcd.translate(translation, relative=True)\n",
    "    return translated_pcd\n",
    "# Load all .pcd files into a dictionary for quick access\n",
    "def load_all_pcds(pcd_file_paths):\n",
    "    pcds_o3d = {}\n",
    "    for pcd_path in pcd_file_paths:\n",
    "        filename = os.path.basename(pcd_path)\n",
    "        pcds_o3d[filename] = o3d.io.read_point_cloud(pcd_path)\n",
    "    return pcds_o3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f02e6fd-fc1a-4742-93fa-f7824d150ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_metrics(metrics_dict, source_filename, target_filename, value):\n",
    "    if source_filename not in metrics_dict:\n",
    "        metrics_dict[source_filename] = []\n",
    "    metrics_dict[source_filename].append((target_filename, value))\n",
    "\n",
    "def rank_metrics(metrics_dict, lower_better=True):\n",
    "    ranking_dict = {}\n",
    "    for key, values in metrics_dict.items():\n",
    "        ranking_dict[key] = sorted(values, key=lambda x: x[1], reverse=not lower_better)\n",
    "    return ranking_dict\n",
    "\n",
    "def scale_align_pcds(pcds_o3d, cube_size):\n",
    "    pcds_downsampled_scaled_and_normals = []\n",
    "    centroids = []\n",
    "\n",
    "    for pcd in pcds_o3d:\n",
    "        obb = pcd.get_oriented_bounding_box()\n",
    "        centroid = obb.center\n",
    "        centroids.append(centroid)\n",
    "    reference_centroid = np.mean(centroids, axis=0)\n",
    "\n",
    "    for pcd in pcds_o3d:\n",
    "        obb = pcd.get_oriented_bounding_box()\n",
    "        extents = obb.extent\n",
    "        scale_factors = np.full(3, cube_size / np.max(extents))\n",
    "        centroid = obb.center\n",
    "        scaled_points = ((np.asarray(pcd.points) - centroid) * scale_factors) + centroid\n",
    "        translation = reference_centroid - centroid\n",
    "        translated_and_scaled_points = scaled_points + translation\n",
    "        pcd_scaled = o3d.geometry.PointCloud()\n",
    "        pcd_scaled.points = o3d.utility.Vector3dVector(translated_and_scaled_points)\n",
    "        pcds_downsampled_scaled_and_normals.append(pcd_scaled)\n",
    "\n",
    "    return pcds_downsampled_scaled_and_normals\n",
    "\n",
    "def main_process(ranking_dict, distance_dict, voxel_size, aspect_ratio_threshold, cube_size, pcds_down_mapped, df_parts):\n",
    "    combined_ratio_dict = {}\n",
    "    index = 1\n",
    "    # Convert the \"part_id_stl_file\" column to a set for faster lookup\n",
    "    valid_parts_set = set(df_parts['part_id_stl_file'])\n",
    "\n",
    "    # Iterate over each part in ranking_dict\n",
    "    for source_filename_stl, similar_parts_stl in ranking_dict.items():\n",
    "        # Check if the source part is in the DataFrame's \"part_id_stl_file\" column\n",
    "        if source_filename_stl not in valid_parts_set:\n",
    "            continue  # Skip this source part if it's not in the DataFrame\n",
    "\n",
    "        # Replace the .stl extension with .pcd for the source filename\n",
    "        source_filename_pcd = source_filename_stl.replace('.stl', '.pcd')\n",
    "        source_pcd = pcds_down_mapped[source_filename_pcd]\n",
    "\n",
    "        # aspect_ratio_source = calculate_aspect_ratio(source_pcd)\n",
    "        # if aspect_ratio_source > aspect_ratio_threshold:\n",
    "        #     # Fetch top 50 tuples from the distance_dict for the given source file\n",
    "        #     if source_filename_stl in distance_dict:\n",
    "        #         top_similar_parts_by_distance = distance_dict[source_filename_stl][:50]\n",
    "        #         # Update combined_ratio_dict with these parts\n",
    "        #         combined_ratio_dict[source_filename_pcd] = top_similar_parts_by_distance\n",
    "        #     continue\n",
    "        top_similar_parts_stl = similar_parts_stl[:50]  # Get top 50 similar parts\n",
    "        for target_filename_stl in top_similar_parts_stl:\n",
    "            target_filename_pcd = target_filename_stl.replace('.stl', '.pcd')\n",
    "            target_pcd = pcds_down_mapped[target_filename_pcd]\n",
    "            # aspect_ratio_target = calculate_aspect_ratio(target_pcd)\n",
    "            # if aspect_ratio_target > aspect_ratio_threshold:\n",
    "            #     update_metrics(combined_ratio_dict, source_filename_pcd, target_filename_pcd, 1)\n",
    "            #     continue                \n",
    "            # Get deep copies for comparison and possible cropping\n",
    "            source_pcd_copy = copy.deepcopy(source_pcd)\n",
    "            target_pcd_copy = copy.deepcopy(target_pcd)\n",
    "\n",
    "            # Crop dimension if needed\n",
    "            \n",
    "            source, target, source_down, target_down, source_fpfh, target_fpfh = prepare_dataset(\n",
    "                voxel_size, [source_pcd_copy, target_pcd_copy])\n",
    "            \n",
    "            result_ransac = execute_global_registration(\n",
    "                source_down, target_down, source_fpfh, target_fpfh, voxel_size, aspect_ratio_threshold)\n",
    "            \n",
    "            source_down.transform(result_ransac.transformation)\n",
    "            result_icp = refine_registration_with_icp(source_down, target_down, voxel_size)\n",
    "            source_down.transform(result_icp.transformation)\n",
    "            combined_ratio = calculate_and_visualize_subtracted_point_clouds(\n",
    "            source_down, target_down, voxel_size)  # Assuming this function calculates the combined ratio\n",
    "            update_metrics(combined_ratio_dict, source_filename_pcd, target_filename_pcd, combined_ratio)\n",
    "\n",
    "            # o3d.visualization.draw_geometries([source_down, target_down])                           \n",
    "        print(index, '# ', source_filename_stl, 'done')\n",
    "        index = index + 1\n",
    "    # Rank the results based on the new combined ratios\n",
    "    combined_ratio_ranking = rank_metrics(combined_ratio_dict, lower_better=True)\n",
    "    return combined_ratio_ranking\n",
    "\n",
    "    \n",
    "#icp final filtered (with long parts dealt with)\n",
    "\n",
    "# def main_process(ranking_dict, distance_dict, voxel_size, aspect_ratio_threshold, cube_size, pcds_down_mapped, df_parts):\n",
    "#     combined_ratio_dict = {}\n",
    "#     index = 1\n",
    "#     # Convert the \"part_id_stl_file\" column to a set for faster lookup\n",
    "#     valid_parts_set = set(df_parts['part_id_stl_file'])\n",
    "    \n",
    "#     # Iterate over each part in ranking_dict\n",
    "#     for source_filename_stl, similar_parts_stl in ranking_dict.items():\n",
    "#         # Check if the source part is in the DataFrame's \"part_id_stl_file\" column\n",
    "#         if source_filename_stl not in valid_parts_set:\n",
    "#             continue  # Skip this source part if it's not in the DataFrame\n",
    "\n",
    "#         # Replace the .stl extension with .pcd for the source filename\n",
    "#         source_filename_pcd = source_filename_stl.replace('.stl', '.pcd')\n",
    "#         source_pcd = pcds_down_mapped[source_filename_pcd]\n",
    "\n",
    "#         aspect_ratio_source = calculate_aspect_ratio(source_pcd)\n",
    "#         if aspect_ratio_source > aspect_ratio_threshold:\n",
    "#             # Fetch top 50 tuples from the distance_dict for the given source file\n",
    "#             if source_filename_stl in distance_dict:\n",
    "#                 top_similar_parts_by_distance = distance_dict[source_filename_stl][:50]\n",
    "#                 # Update combined_ratio_dict with these parts\n",
    "#                 combined_ratio_dict[source_filename_pcd] = top_similar_parts_by_distance\n",
    "#             continue\n",
    "#         top_similar_parts_stl = similar_parts_stl[:50]  # Get top 50 similar parts\n",
    "#         for target_filename_stl in top_similar_parts_stl:\n",
    "#             target_filename_pcd = target_filename_stl.replace('.stl', '.pcd')\n",
    "#             target_pcd = pcds_down_mapped[target_filename_pcd]\n",
    "#             aspect_ratio_target = calculate_aspect_ratio(target_pcd)\n",
    "#             if aspect_ratio_target > aspect_ratio_threshold:\n",
    "#                 update_metrics(combined_ratio_dict, source_filename_pcd, target_filename_pcd, 1)\n",
    "#                 continue                \n",
    "#             # Get deep copies for comparison and possible cropping\n",
    "#             source_pcd_copy = copy.deepcopy(source_pcd)\n",
    "#             target_pcd_copy = copy.deepcopy(target_pcd)\n",
    "\n",
    "#             # Crop dimension if needed\n",
    "            \n",
    "#             source, target, source_down, target_down, source_fpfh, target_fpfh = prepare_dataset(\n",
    "#                 voxel_size, [source_pcd_copy, target_pcd_copy])\n",
    "            \n",
    "#             result_ransac = execute_global_registration(\n",
    "#                 source_down, target_down, source_fpfh, target_fpfh, voxel_size, aspect_ratio_threshold)\n",
    "            \n",
    "#             # Assuming result_ransac and result_icp operations are successful\n",
    "#             if result_ransac:\n",
    "#                 source_down.transform(result_ransac.transformation)\n",
    "#                 result_icp = refine_registration_with_icp(source_down, target_down, voxel_size)\n",
    "#                 source_down.transform(result_icp.transformation)\n",
    "#                 combined_ratio = calculate_and_visualize_subtracted_point_clouds(\n",
    "#                 source_down, target_down, voxel_size)  # Assuming this function calculates the combined ratio\n",
    "#                 update_metrics(combined_ratio_dict, source_filename_pcd, target_filename_pcd, combined_ratio) \n",
    "#             # o3d.visualization.draw_geometries([source_down, target_down])                           \n",
    "#         print(index, '# ', source_filename_stl, 'done')\n",
    "#         index = index + 1\n",
    "#     # Rank the results based on the new combined ratios\n",
    "#     combined_ratio_ranking = rank_metrics(combined_ratio_dict, lower_better=True)\n",
    "#     return combined_ratio_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9778e24b-386b-426f-8eab-0380bdab030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('ranking_dict.pkl', 'rb') as file:\n",
    "    ranking_dict = pickle.load( file)\n",
    "\n",
    "with open('distance_dict.pkl', 'rb') as file:\n",
    "    distance_dict = pickle.load( file)\n",
    "\n",
    "with open('scores_dict.pkl', 'rb') as file:\n",
    "    scores_dict = pickle.load( file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d8cd1c5-0c96-469c-bebe-bd62f1fce297",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assuming the directories are already defined as in your code\n",
    "# Assuming the directories are already defined as in your code\n",
    "current_dir = os.getcwd()\n",
    "ermetal_dir = os.path.join(current_dir, 'ermetal')\n",
    "pcd_directory = os.path.join(current_dir, 'pcds_20k_random')\n",
    "\n",
    "# Make sure the pcd directory exists, create if it does not\n",
    "os.makedirs(pcd_directory, exist_ok=True)\n",
    "\n",
    "stl_file_paths = [os.path.join(ermetal_dir, f) for f in os.listdir(ermetal_dir) if f.endswith('.stl')]\n",
    "stl_file_names = [os.path.basename(f) for f in stl_file_paths]\n",
    "\n",
    "obb_extents_dict = {}  # Dictionary to store the sorted extents\n",
    "pcds_o3d = []\n",
    "voxel_size = 0.06\n",
    "aspect_ratio_threshold = 14   # Adjust based on your requirements\n",
    "cube_size = 1.5\n",
    "\n",
    "for i, stl_file in enumerate(stl_file_names):\n",
    "    pcd_file_name = stl_file.replace('.stl', '.pcd')\n",
    "    pcd_file_path = os.path.join(pcd_directory, pcd_file_name)\n",
    "\n",
    "    # Check if the .pcd file already exists\n",
    "    if os.path.exists(pcd_file_path):\n",
    "        # Read the existing point cloud\n",
    "        point_cloud = o3d.io.read_point_cloud(pcd_file_path)\n",
    "        # print(f\"Read existing point cloud: {pcd_file_path}\")\n",
    "    else:\n",
    "        # Process the mesh to generate a new point cloud\n",
    "        mesh_path = os.path.join(ermetal_dir, stl_file)\n",
    "        mesh = o3d.io.read_triangle_mesh(mesh_path)\n",
    "\n",
    "        # Compute the OBB and get sorted extents\n",
    "        obb = mesh.get_oriented_bounding_box()\n",
    "        extents = sorted(obb.extent)  # Sort extents in ascending order\n",
    "        obb_extents_dict[stl_file] = extents\n",
    "\n",
    "        point_cloud = mesh.sample_points_uniformly(number_of_points=20_000)\n",
    "        o3d.io.write_point_cloud(pcd_file_path, point_cloud)\n",
    "        print(f\"Generated and saved point cloud: {pcd_file_path}\")\n",
    "\n",
    "    pcds_o3d.append(point_cloud)\n",
    "\n",
    "# Normalize and estimate normals for the point clouds\n",
    "pcds_down = scale_align_pcds(pcds_o3d, cube_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f252f96-fcea-495c-8e4b-f1ab3718799f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 #  003_2021_Teklifid_2318.stl done\n",
      "2 #  004_2020_Teklifid_342.stl done\n",
      "3 #  007_2020_Teklifid_142.stl done\n",
      "4 #  007_2021_Teklifid_2365.stl done\n",
      "5 #  017_2020_Teklifid_286.stl done\n",
      "6 #  024_2021_Teklifid_2397.stl done\n",
      "7 #  029_2020_Teklifid_380.stl done\n",
      "8 #  036_2020_Teklifid_404.stl done\n",
      "9 #  037_2021_Teklifid_2457.stl done\n",
      "10 #  040_2020_Teklifid_441.stl done\n",
      "11 #  053_2022_Teklifid_3974.stl done\n",
      "12 #  053_2022_Teklifid_3982.stl done\n",
      "13 #  063_2020_Teklifid_732.stl done\n",
      "14 #  064_2022_Teklifid_4015.stl done\n",
      "15 #  070_2022_Teklifid_4075.stl done\n",
      "16 #  073_2021_Teklifid_2570.stl done\n",
      "17 #  073_2021_Teklifid_2574.stl done\n",
      "18 #  093_2020_Teklifid_804.stl done\n",
      "19 #  098_2022_Teklifid_4112.stl done\n",
      "20 #  098_2022_Teklifid_4135.stl done\n",
      "21 #  099_2022_Teklifid_4141.stl done\n",
      "22 #  106_2020_Teklifid_918.stl done\n",
      "23 #  114_2020_Teklifid_1047.stl done\n",
      "24 #  114_2020_Teklifid_933.stl done\n",
      "25 #  114_2020_Teklifid_935.stl done\n",
      "26 #  120_2020_Teklifid_994.stl done\n",
      "27 #  121_2020_Teklifid_1010.stl done\n",
      "28 #  121_2020_Teklifid_1019.stl done\n",
      "29 #  121_2020_Teklifid_1026.stl done\n",
      "30 #  121_2020_Teklifid_1034.stl done\n",
      "31 #  121_2020_Teklifid_1689.stl done\n",
      "32 #  122_2020_Teklifid_1091.stl done\n",
      "33 #  122_2020_Teklifid_1103.stl done\n",
      "34 #  129_2020_Teklifid_1143.stl done\n",
      "35 #  140_2020_Teklifid_1212.stl done\n",
      "36 #  142_2020_Teklifid_1268.stl done\n",
      "37 #  142_2020_Teklifid_1269.stl done\n",
      "38 #  142_2020_Teklifid_1374.stl done\n",
      "39 #  142_2020_Teklifid_1412.stl done\n",
      "40 #  142_2020_Teklifid_1821.stl done\n",
      "41 #  142_2020_Teklifid_1837.stl done\n",
      "42 #  147_2022_Teklifid_4218.stl done\n",
      "43 #  173_2020_Teklifid_1668.stl done\n",
      "44 #  184_2022_Teklifid_4342.stl done\n",
      "45 #  191_2021_Teklifid_2908.stl done\n",
      "46 #  228_2020_Teklifid_1921.stl done\n",
      "47 #  228_2020_Teklifid_1958.stl done\n",
      "48 #  228_2020_Teklifid_1967.stl done\n",
      "49 #  295_2021_Teklifid_3012.stl done\n",
      "50 #  335_2021_Teklifid_3045.stl done\n",
      "51 #  543_2021_Teklifid_3251.stl done\n",
      "52 #  543_2021_Teklifid_3276.stl done\n",
      "53 #  543_2021_Teklifid_3308.stl done\n",
      "54 #  543_2021_Teklifid_3311.stl done\n",
      "55 #  543_2021_Teklifid_3312.stl done\n",
      "56 #  543_2021_Teklifid_3322.stl done\n",
      "57 #  997_2021_Teklifid_3831.stl done\n",
      "58 #  997_2021_Teklifid_3832.stl done\n",
      "59 #  997_2021_Teklifid_3834.stl done\n",
      "60 #  997_2021_Teklifid_3835.stl done\n",
      "61 #  997_2021_Teklifid_3861.stl done\n",
      "62 #  997_2021_Teklifid_3882.stl done\n",
      "63 #  997_2021_Teklifid_3924.stl done\n",
      "64 #  997_2021_Teklifid_3926.stl done\n",
      "65 #  997_2021_Teklifid_3929.stl done\n",
      "66 #  997_2021_Teklifid_3931.stl done\n",
      "67 #  997_2021_Teklifid_3933.stl done\n",
      "68 #  997_2021_Teklifid_3935.stl done\n",
      "69 #  997_2021_Teklifid_3936.stl done\n",
      "70 #  997_2021_Teklifid_3940.stl done\n",
      "71 #  997_2021_Teklifid_3941.stl done\n"
     ]
    }
   ],
   "source": [
    "voxel_size = 0.06\n",
    "aspect_ratio_threshold = 14   # Adjust based on your requirements\n",
    "cube_size = 1.5\n",
    "# Assuming stl_file_names and pcds_down are already defined and correspond to each other\n",
    "pcds_mapped = {stl_file_name.replace('.stl', '.pcd'): pcd for stl_file_name, pcd in zip(stl_file_names, pcds_down)}\n",
    "curr=os.getcwd()\n",
    "df_parts = pd.read_excel(curr+'\\\\labelled_files.xlsx')\n",
    "# Call the main process function\n",
    "combined_ratio_ranking = main_process(ranking_dict,distance_dict, voxel_size, aspect_ratio_threshold, cube_size, pcds_mapped,df_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c442b44-82b2-4e85-b47f-6591d68f8839",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(combined_ratio_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e07e97a-4074-4e10-be87-2df3bad7db9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('icp_filtered_only.pkl','wb') as file:\n",
    "#     pickle.dump(combined_ratio_ranking, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d5b9de2-1cbf-402d-91c5-e7ee6f812588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('icp_filtered_final.pkl','rb') as file:\n",
    "    combined_ratio_ranking =  pickle.load( file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a9d948d-5d41-4ec1-a578-ee7acbb0084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert .pcd extensions to .stl for both keys and values\n",
    "combined_ratio_ranking_stl = {\n",
    "    key.replace('.pcd', '.stl'): [(filename.replace('.pcd', '.stl'), score) for filename, score in value]\n",
    "    for key, value in combined_ratio_ranking.items()\n",
    "}\n",
    "\n",
    "\n",
    "# scores_dict = {   \n",
    "#     key: [scores for _, scores in value]\n",
    "#     for key, value in combined_ratio_ranking_stl.items()\n",
    "# }\n",
    "# # # Create a new dictionary with .stl filenames without the scores\n",
    "# ranking_dict = {\n",
    "#     key: [filename for filename, _ in value]\n",
    "#     for key, value in combined_ratio_ranking_stl.items()\n",
    "# }\n",
    "\n",
    "# Print or return ranking_dict as needed\n",
    "# print(ranking_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "311db2bc-e3ff-4176-a0d5-670d20232e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dict = {   \n",
    "    key: [scores for _, scores in value]\n",
    "    for key, value in combined_ratio_ranking_stl.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75c7ce45-3fe5-4d61-aaf4-460ac3cf780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_dict = {\n",
    "    key: [filename for filename, _ in value]\n",
    "    for key, value in combined_ratio_ranking_stl.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a838fff8-cbc2-4dbf-8fb6-9e4e34a31b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['part_id_stl_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "818113c9-6496-46bb-b311-563baa82597c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "543_2021_Teklifid_3322.stl: matching file 543_2021_Teklifid_3323.stl is beyond top 5, ranked at 49\n",
      "098_2022_Teklifid_4135.stl: matching file 098_2022_Teklifid_4134.stl is beyond top 5, ranked at 11\n",
      "543_2021_Teklifid_3251.stl: matching file 008_2021_Teklifid_2332.stl is beyond top 5, ranked at 24\n",
      "543_2021_Teklifid_3276.stl: matching file 543_2021_Teklifid_3277.stl is beyond top 5, ranked at 10\n",
      "098_2022_Teklifid_4112.stl: matching file 098_2022_Teklifid_4113.stl is beyond top 5, ranked at 11\n",
      "140_2020_Teklifid_1212.stl: matching file 140_2020_Teklifid_1211.stl is beyond top 5, ranked at 35\n",
      "target file 543_2021_Teklifid_3322.stl :  [('079_2020_Teklifid_741.stl', 62.62362838426717), ('121_2020_Teklifid_1073.stl', 71.43501690954722), ('543_2021_Teklifid_3271.stl', 74.49047734282445), ('997_2021_Teklifid_3903.stl', 77.43767870605812), ('106_2021_Teklifid_2612.stl', 86.77838930986992), ('007_2021_Teklifid_2335.stl', 86.99158667543169), ('067_2022_Teklifid_4074.stl', 91.51234950741727), ('017_2020_Teklifid_310.stl', 97.81973741875473), ('176_2021_Teklifid_2904.stl', 110.93390739739925), ('001_2020_Teklifid_11.stl', 111.35984365246841), ('245_2020_Teklifid_2046.stl', 114.2587953741469), ('997_2021_Teklifid_3847.stl', 115.36377161337369), ('029_2020_Teklifid_383.stl', 120.73476674213204), ('040_2020_Teklifid_504.stl', 121.93674109480375), ('029_2020_Teklifid_391.stl', 124.5485105959486), ('114_2020_Teklifid_938.stl', 128.5087140363413), ('068_2020_Teklifid_681.stl', 131.53036631998353), ('178_2021_Teklifid_2902.stl', 132.46499752240356), ('121_2020_Teklifid_1007.stl', 135.99174899454366), ('007_2020_Teklifid_157.stl', 137.36879580747927), ('053_2022_Teklifid_3989.stl', 137.49156665300404), ('936_2021_Teklifid_3789.stl', 140.24990533987935), ('543_2021_Teklifid_3307.stl', 142.0688295487979), ('202_2020_Teklifid_1806.stl', 143.0541296514494), ('079_2020_Teklifid_740.stl', 144.4953961523746), ('142_2020_Teklifid_1393.stl', 144.4956275945233), ('053_2022_Teklifid_3983.stl', 144.5003393903134), ('001_2020_Teklifid_5.stl', 148.34676951894684), ('335_2021_Teklifid_3045.stl', 148.48921655284641), ('335_2021_Teklifid_3046.stl', 150.21452623515842), ('184_2022_Teklifid_4376.stl', 151.9559930318816), ('053_2022_Teklifid_3985.stl', 155.43148006469755), ('004_2020_Teklifid_113.stl', 156.13769314320461), ('142_2020_Teklifid_1386.stl', 157.91182373787908), ('142_2020_Teklifid_1389.stl', 158.28280509856694), ('053_2022_Teklifid_4001.stl', 160.70248319931093), ('037_2021_Teklifid_2458.stl', 161.16632826620236), ('997_2021_Teklifid_3883.stl', 161.88379210564898), ('936_2021_Teklifid_3792.stl', 162.14042990973968), ('157_2020_Teklifid_1664.stl', 162.4081270581025), ('997_2021_Teklifid_3839.stl', 164.25107806979213), ('159_2022_Teklifid_4253.stl', 165.85295284486486), ('029_2020_Teklifid_381.stl', 167.06725659285922), ('070_2022_Teklifid_4072.stl', 167.4871016371413), ('142_2020_Teklifid_1415.stl', 167.57552946853406), ('007_2021_Teklifid_2337.stl', 168.0300661272628), ('133_2020_Teklifid_1184.stl', 168.962698243446), ('174_2021_Teklifid_2883.stl', 169.84965075304473), ('543_2021_Teklifid_3323.stl', 170.25323391535704), ('543_2021_Teklifid_3308.stl', 170.3720775591856)] \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 121\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;66;03m# print('ermetal top choice', top_choice, \": \", scores_dict[top_choice],'\\n')\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# print('target file',stl_file,': ',normalized_dict[stl_file],\"\\n\")\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;66;03m# print('algorithm top match #',i+1, top_matches[i],\": \",combined_ratio_ranking_stl[top_matches[i]],'\\n')\u001b[39;00m\n\u001b[0;32m    118\u001b[0m         \u001b[38;5;66;03m# print('algorithm top match #',i+1, top_matches[i],\": \",normalized_dict[top_matches[i]],'\\n')\u001b[39;00m\n\u001b[0;32m    120\u001b[0m     visualize_filenames \u001b[38;5;241m=\u001b[39m [stl_file, top_choice] \u001b[38;5;241m+\u001b[39m top_matches\n\u001b[1;32m--> 121\u001b[0m     \u001b[43mvisualize_meshes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvisualize_filenames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirectory_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# 997_2021_Teklifid_3933.stl: matching file 997_2021_Teklifid_3938.stl is beyond top 5, ranked at 7\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# 543_2021_Teklifid_3322.stl: matching file 543_2021_Teklifid_3323.stl is beyond top 5, ranked at 34\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# 098_2022_Teklifid_4135.stl: matching file 098_2022_Teklifid_4134.stl is beyond top 5, ranked at 12\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# 098_2022_Teklifid_4112.stl: matching file 098_2022_Teklifid_4113.stl is beyond top 5, ranked at 10\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m# 140_2020_Teklifid_1212.stl: matching file 140_2020_Teklifid_1211.stl is beyond top 5, ranked at 29\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "a = ''\n",
    "# Read the Excel file\n",
    "curr=os.getcwd()\n",
    "\n",
    "df = pd.read_excel(curr+'\\\\labelled_files.xlsx')\n",
    "\n",
    "# Loop through the dataframe\n",
    "for index, row in df.iterrows():\n",
    "    stl_file_name = row['part_id_stl_file']\n",
    "    top_choice = row['top_choice_stl_file']\n",
    "\n",
    "    # Check if stl_file_name is in ranking_dict\n",
    "    if stl_file_name in ranking_dict:\n",
    "        ranking = ranking_dict[stl_file_name]\n",
    "        \n",
    "        # Check if the top choice matches the first rank in ranking_dict\n",
    "        if ranking[0] == top_choice:\n",
    "            # print(f\"{stl_file_name}: matching file {top_choice} has rank 1\")\n",
    "            pass\n",
    "        else:\n",
    "            \n",
    "            # Find the rank of the top choice in the ranking list\n",
    "            if top_choice in ranking:\n",
    "                rank = ranking.index(top_choice) + 1\n",
    "                if rank <= 5:\n",
    "                    # print(f\"{stl_file_name}: matching file {top_choice} has rank {rank}\")\n",
    "                    pass\n",
    "                else:\n",
    "                    print(f\"{stl_file_name}: matching file {top_choice} is beyond top 5, ranked at {rank}\")\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "                # print(f\"{stl_file_name}: matching file {top_choice} is not ranked\")\n",
    "    else:\n",
    "        print(f\"{stl_file_name} is not in the ranking dictionary\")\n",
    "\n",
    "#ALIGNMENT AND VISUALIZATION FUNCTIONS \n",
    "\n",
    "def visualize_mesh_with_triangles(mesh):\n",
    "    \"\"\"Visualizes a mesh with colored triangles and black lines along the edges of the triangles.\"\"\"\n",
    "\n",
    "    # mesh = translate_mesh_to_origin(mesh)\n",
    "    vertex_colors = np.full((len(np.asarray(mesh.vertices)), 3), [0.8, 0.8, 0.8])\n",
    "    mesh.vertex_colors = o3d.utility.Vector3dVector(vertex_colors)\n",
    "    lines = [[triangle[0], triangle[1]] for triangle in np.asarray(mesh.triangles)] + \\\n",
    "            [[triangle[1], triangle[2]] for triangle in np.asarray(mesh.triangles)] + \\\n",
    "            [[triangle[2], triangle[0]] for triangle in np.asarray(mesh.triangles)]\n",
    "    line_set = o3d.geometry.LineSet(\n",
    "        points=o3d.utility.Vector3dVector(np.asarray(mesh.vertices)),\n",
    "        lines=o3d.utility.Vector2iVector(lines),\n",
    "    )\n",
    "    line_set.paint_uniform_color([0, 0, 0])\n",
    "    return [mesh, line_set]\n",
    "\n",
    "def visualize_meshes(filenames, directory_path):\n",
    "    geometries_to_show = []\n",
    "    current_x_position = 50\n",
    "    spacing_factor = 3.5  # Adjust this factor to control spacing between the meshes\n",
    "\n",
    "    for i, filename in enumerate(filenames):\n",
    "        full_path = os.path.join(directory_path, filename)\n",
    "        mesh_open3d = o3d.io.read_triangle_mesh(full_path)\n",
    "        # mesh_open3d = align_mesh(mesh_open3d)\n",
    "        # Compute the axis-aligned bounding box to get the x dimension\n",
    "        aabb = mesh_open3d.get_axis_aligned_bounding_box()\n",
    "        x_dim = aabb.get_extent()[0]\n",
    "        # For the first mesh (target mesh), we start at (0,0,0) and account for its size in spacing\n",
    "        if i == 0:\n",
    "            mesh_open3d.translate(-aabb.get_center())\n",
    "        else:\n",
    "            mesh_open3d.translate((current_x_position, 0, 0) - aabb.get_center())\n",
    "        geometries_to_show.extend(visualize_mesh_with_triangles(mesh_open3d))\n",
    "        current_x_position += x_dim * spacing_factor  # Update the x position\n",
    "    \n",
    "    o3d.visualization.draw_geometries(geometries_to_show)\n",
    "\n",
    "#ALIGNMENT AND VISUALIZATION FUNCTIONS \n",
    "\n",
    "#VISUALIZE BAD EXAMPLES, THE FIRST ONE IS THE TARGET PART, SECOND ONE IS THE ERMETAL TOP CHOICE, AND THE REST ARE ALGORITHM CHOICES\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# loading ermetal stl meshes\n",
    "# stl_directory = os.path.join(current_dir,'updated_stl')\n",
    "stl_directory = os.path.join(current_dir,'ermetal')\n",
    "\n",
    "pcd_directory = os.path.join(current_dir,'pcd_5k')\n",
    "# Initialize a list to store filenames for visualization along with their top choices\n",
    "files_to_visualize_with_top_choice = []\n",
    "\n",
    "# Loop through the dataframe\n",
    "for index, row in df.iterrows():\n",
    "    stl_file_name = row['part_id_stl_file']\n",
    "    top_choice = row['top_choice_stl_file']\n",
    "\n",
    "    if stl_file_name in ranking_dict:\n",
    "        ranking = ranking_dict[stl_file_name]\n",
    "\n",
    "        if ranking[0] != top_choice and top_choice in ranking:\n",
    "            rank = ranking.index(top_choice) + 1\n",
    "            if rank > 5:\n",
    "                # Add the STL file, its top choice, and its top 5 similar parts to the visualization list\n",
    "                files_to_visualize_with_top_choice.append((stl_file_name, top_choice, ranking[:3]))\n",
    "    else:\n",
    "        print(f\"{stl_file_name} is not in the ranking dictionary\")\n",
    "\n",
    "# Visualize the collected STL files, their top choices, and their top 5 similar parts\n",
    "directory_path = stl_directory  # Replace with the actual path to your STL files\n",
    "for stl_file, top_choice, top_matches in files_to_visualize_with_top_choice:\n",
    "    print('target file',stl_file,': ',combined_ratio_ranking_stl[stl_file],\"\\n\")\n",
    "    # print('ermetal top choice', top_choice, \": \", scores_dict[top_choice],'\\n')\n",
    "\n",
    "    # print('target file',stl_file,': ',normalized_dict[stl_file],\"\\n\")\n",
    "    # print('ermetal top choice', top_choice, \": \", normalized_dict[top_choice],'\\n')\n",
    "    \n",
    "    # for i in range(len(top_matches)):\n",
    "        # print('algorithm top match #',i+1, top_matches[i],\": \",combined_ratio_ranking_stl[top_matches[i]],'\\n')\n",
    "        # print('algorithm top match #',i+1, top_matches[i],\": \",normalized_dict[top_matches[i]],'\\n')\n",
    "        \n",
    "    visualize_filenames = [stl_file, top_choice] + top_matches\n",
    "    visualize_meshes(visualize_filenames, directory_path)\n",
    "\n",
    "\n",
    "\n",
    "# 997_2021_Teklifid_3933.stl: matching file 997_2021_Teklifid_3938.stl is beyond top 5, ranked at 7\n",
    "# 543_2021_Teklifid_3322.stl: matching file 543_2021_Teklifid_3323.stl is beyond top 5, ranked at 34\n",
    "# 098_2022_Teklifid_4135.stl: matching file 098_2022_Teklifid_4134.stl is beyond top 5, ranked at 12\n",
    "# 543_2021_Teklifid_3251.stl: matching file 008_2021_Teklifid_2332.stl is beyond top 5, ranked at 19\n",
    "# 543_2021_Teklifid_3311.stl: matching file 543_2021_Teklifid_3312.stl is beyond top 5, ranked at 12\n",
    "# 997_2021_Teklifid_3926.stl: matching file 997_2021_Teklifid_3931.stl is beyond top 5, ranked at 13\n",
    "# 120_2020_Teklifid_994.stl: matching file 120_2020_Teklifid_989.stl is beyond top 5, ranked at 45\n",
    "# 098_2022_Teklifid_4112.stl: matching file 098_2022_Teklifid_4113.stl is beyond top 5, ranked at 33\n",
    "# 140_2020_Teklifid_1212.stl: matching file 140_2020_Teklifid_1211.stl is beyond top 5, ranked at 27\n",
    "\n",
    "# 036_2020_Teklifid_404.stl: matching file 309_2021_Teklifid_3029.stl is beyond top 5, ranked at 28\n",
    "# 997_2021_Teklifid_3933.stl: matching file 997_2021_Teklifid_3938.stl is beyond top 5, ranked at 7\n",
    "# 543_2021_Teklifid_3251.stl: matching file 008_2021_Teklifid_2332.stl is beyond top 5, ranked at 43\n",
    "# 120_2020_Teklifid_994.stl: matching file 120_2020_Teklifid_989.stl is beyond top 5, ranked at 46\n",
    "# 543_2021_Teklifid_3276.stl: matching file 543_2021_Teklifid_3277.stl is beyond top 5, ranked at 7\n",
    "# 098_2022_Teklifid_4112.stl: matching file 098_2022_Teklifid_4113.stl is beyond top 5, ranked at 31\n",
    "# 140_2020_Teklifid_1212.stl: matching file 140_2020_Teklifid_1211.stl is beyond top 5, ranked at 25\n",
    "\n",
    "# 121_2020_Teklifid_1034.stl: matching file 121_2020_Teklifid_1035.stl is beyond top 5, ranked at 6\n",
    "# 228_2020_Teklifid_1921.stl: matching file 228_2020_Teklifid_1922.stl is beyond top 5, ranked at 7\n",
    "# 997_2021_Teklifid_3933.stl: matching file 997_2021_Teklifid_3938.stl is beyond top 5, ranked at 11\n",
    "# 997_2021_Teklifid_3882.stl: matching file 997_2021_Teklifid_3915.stl is beyond top 5, ranked at 21\n",
    "# 228_2020_Teklifid_1921.stl: matching file 228_2020_Teklifid_1922.stl is beyond top 5, ranked at 7\n",
    "# 543_2021_Teklifid_3322.stl: matching file 543_2021_Teklifid_3323.stl is beyond top 5, ranked at 50\n",
    "# 098_2022_Teklifid_4135.stl: matching file 098_2022_Teklifid_4134.stl is beyond top 5, ranked at 11\n",
    "# 543_2021_Teklifid_3251.stl: matching file 008_2021_Teklifid_2332.stl is beyond top 5, ranked at 23\n",
    "# 098_2022_Teklifid_4112.stl: matching file 098_2022_Teklifid_4113.stl is beyond top 5, ranked at 10\n",
    "# 140_2020_Teklifid_1212.stl: matching file 140_2020_Teklifid_1211.stl is beyond top 5, ranked at 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4150b1-be5d-43f1-897e-93c2c6cdd2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3df581d-31f7-4676-8e01-49625ce567d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_dict['036_2020_Teklifid_404.stl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e679d02-1bba-46a1-ad96-d1e7ac42acac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
